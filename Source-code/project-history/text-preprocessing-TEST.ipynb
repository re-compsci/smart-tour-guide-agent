{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80635df9",
   "metadata": {},
   "source": [
    "<h1>Smart Tour Guide Bot</h1>\n",
    "\n",
    "**Project Title:**\n",
    "Multimodal AI Travel Assistant\n",
    "\n",
    "**Names:**\n",
    "\n",
    "- Renad Naser\n",
    "- ⁠Amjad Althagafi\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "In a world with many transportations and countries, many people are becoming excited about the visiting new places and discover new things. \n",
    "Nowadays, the internet is full with many resources which make it difficult to find a specific information with being sure that it is correct or enough.\n",
    "\n",
    "So we design and deploy an intelligent AI chatbot that answers user travel-related questions using voice or text, by extracting and summarizing data from global travel guide sources.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This project aims to build a multimodal RAG chatbot that allows users to ask questions and requests, like —“What can I visit in Paris in 2 days?”—and receive instant, accurate responses. The chatbot uses speech recognition, and summarize relevant information from tourist guides like Wikivoyage. It supports both text and voice input and provides responses using pre-trained transformer models.\n",
    "\n",
    "**AI Techniques:**\n",
    "\n",
    "\t•\tSpeech Recognition (Whisper by OpenAI)\n",
    "\t•\tText Chunking & Embedding (LangChain + HuggingFace Transformers)\n",
    "\t•\tVector Search (ChromaDB or FAISS DB)\n",
    "\t•\tMultimodal RAG system\n",
    "\t•\tConversational Agents with Memory (LangChain Agents)\n",
    "\t•\tLangSmith for evaluation\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "\t•\tSmart travel planning assistants\n",
    "\t•\tAccessibility tools for visually/hearing-impaired travelers\n",
    "\t•\tEducational tools for learning about geography and culture\n",
    "\t•\tChatbots for tourism websites or mobile travel apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb22b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\riina\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: pyowm in c:\\users\\riina\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\riina\\anaconda3\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from pyowm) (2.32.3)\n",
      "Requirement already satisfied: geojson<3,>=2.3.0 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from pyowm) (2.5.0)\n",
      "Requirement already satisfied: PySocks<2,>=1.7.1 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from pyowm) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from requests<3,>=2.20.0->pyowm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from requests<3,>=2.20.0->pyowm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from requests<3,>=2.20.0->pyowm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\riina\\anaconda3\\lib\\site-packages (from requests<3,>=2.20.0->pyowm) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcadbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from typing import Dict, List, Any\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.tools import Tool\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper,WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8577c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb425cd1",
   "metadata": {},
   "source": [
    "step 1 : creat wiki function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fffd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Riyadh, the current weather is as follows:\\nDetailed status: overcast clouds\\nWind speed: 4.12 m/s, direction: 119°\\nHumidity: 9%\\nTemperature: \\n  - Current: 32.32°C\\n  - High: 32.32°C\\n  - Low: 32.32°C\\n  - Feels like: 30.04°C\\nRain: {}\\nHeat index: None\\nCloud cover: 100%'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_api = OpenWeatherMapAPIWrapper()  #https://home.openweathermap.org/api_keys\n",
    "\n",
    "wiki_api = WikipediaAPIWrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4699eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs(article):\n",
    "  return Document(\n",
    "      page_content=article['text'],\n",
    "      metadata={\"title\": article['title']}\n",
    "  )\n",
    "\n",
    "documents = []\n",
    "for raw in data:\n",
    " documents.append(docs(raw))\n",
    "\n",
    "documents\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents()#.split_text(data)\n",
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1dd00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fb4d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b35591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_search(query):\n",
    "    data = wiki_api.load(query)\n",
    "    split_docs =  splitter.split_documents(data)\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(split_docs, embed)\n",
    "\n",
    "# 5. Create retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f722a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"faiss.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d79a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "# from google.colab import userdata\n",
    "# api_key = userdata.get('OPENAI_API')\n",
    "llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo-instruct\")  # or \"gpt-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "958dc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval method 1\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm ,  # Swap with HuggingFaceHub or others if needed\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17f0cd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "  Paris is the capital and largest city of France.\n",
      "\n",
      "Sources:\n",
      " [Document(id='48bdb864-78d1-4957-a0b6-d82d6a6c906b', metadata={'title': 'April'}, page_content='London, United Kingdom\\n Madrid, Spain\\n Paris, France\\n Rotterdam, Netherlands\\n Utrecht, Netherlands\\n Zurich, Switzerland'), Document(id='1f936bc6-b39e-4328-9e71-2dd0533d321f', metadata={'title': 'Algebra'}, page_content='History'), Document(id='ce24d367-c2e5-4399-b844-ff549dba2e27', metadata={'title': 'Afghanistan'}, page_content='History'), Document(id='7bc39256-2a55-47d0-b7ef-aa29f65fa819', metadata={'title': 'Armenia'}, page_content='History')]\n"
     ]
    }
   ],
   "source": [
    "query = query = \"What is paris?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "print(\"\\nSources:\\n\", result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bab0a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "  I'm sorry, I cannot make a trip plan as I am a text-based program. However, I can provide information about events and locations in Paris.\n",
      "\n",
      "Sources:\n",
      " [Document(id='48bdb864-78d1-4957-a0b6-d82d6a6c906b', metadata={'title': 'April'}, page_content='London, United Kingdom\\n Madrid, Spain\\n Paris, France\\n Rotterdam, Netherlands\\n Utrecht, Netherlands\\n Zurich, Switzerland'), Document(id='8785d90c-3ab9-4d1a-a6e5-5017a7e17977', metadata={'title': 'December'}, page_content='Moveable and Non-Single Day Events'), Document(id='cdb38401-2449-42ef-82f5-99a56417740f', metadata={'title': 'August'}, page_content='Moveable and Monthlong events'), Document(id='0788060d-86b0-4402-8cba-a36865fa22ac', metadata={'title': 'Austria'}, page_content='Food')]\n"
     ]
    }
   ],
   "source": [
    "query = \"can you make a trip plan for 2 days in paris?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "print(\"\\nSources:\\n\", result[\"source_documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "\n",
    "# # Set your API key\n",
    "# openai.api_key = \"your-api-key\"\n",
    "\n",
    "# # === Step 1: Function to classify and extract topic ===\n",
    "# def classify_request(user_input: str) -> tuple:\n",
    "#     prompt = f\"\"\"\n",
    "# Classify the user's request as one of the following categories:\n",
    "# - \"weather\"\n",
    "# - \"wikipedia\"\n",
    "# - \"other\"\n",
    "\n",
    "# Then extract the main topic or location.\n",
    "\n",
    "# User request: \"{user_input}\"\n",
    "# Category:\n",
    "# Topic:\n",
    "# \"\"\"\n",
    "\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         temperature=0,\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#         max_tokens=60\n",
    "#     )\n",
    "\n",
    "#     content = response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "#     # Simple parsing\n",
    "#     lines = content.splitlines()\n",
    "#     category = \"\"\n",
    "#     topic = \"\"\n",
    "#     for line in lines:\n",
    "#         if line.lower().startswith(\"category\"):\n",
    "#             category = line.split(\":\")[1].strip().lower()\n",
    "#         elif line.lower().startswith(\"topic\"):\n",
    "#             topic = line.split(\":\")[1].strip()\n",
    "#     return category, topic\n",
    "\n",
    "\n",
    "# # === Step 2: Simulated API calls ===\n",
    "# def call_weather_api(location: str):\n",
    "#     data = weather_api.run(location)\n",
    "#     # temperature and humidity\n",
    "#     return f\"Temperature and humidity in {location}: {data}\"\n",
    "\n",
    "# def call_wikipedia_api(topic: str):\n",
    "#     data = wiki_api.run(topic)\n",
    "#     return f\"Here's a summary about {topic}: '...'\"  # mock response\n",
    "\n",
    "\n",
    "# # === Step 3: Router ===\n",
    "# def handle_user_request(user_input: str) -> str:\n",
    "#     category, topic = classify_request(user_input)\n",
    "\n",
    "#     if category == \"weather\":\n",
    "#         return call_weather_api(topic)\n",
    "#     elif category == \"wikipedia\":\n",
    "#         return call_wikipedia_api(topic)\n",
    "#     else:\n",
    "#         return \"Sorry, I can't help with that type of request yet.\"\n",
    "\n",
    "\n",
    "# # === Step 4: Test Example ===\n",
    "# if __name__ == \"__main__\":\n",
    "#     user_input = input(\"User: \")\n",
    "#     result = handle_user_request(user_input)\n",
    "#     print(\"Agent:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
